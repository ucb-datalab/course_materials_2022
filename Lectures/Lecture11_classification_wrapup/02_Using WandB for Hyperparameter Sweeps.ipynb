{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "worst-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "<style>\n",
       "\n",
       "@import url(https://fonts.googleapis.com/css?family=Open+Sans);body{\n",
       "   font-family: 'Open Sans';\n",
       "   font-size: 125%;\n",
       "}\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 275%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.3; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-gallery",
   "metadata": {},
   "source": [
    "# Monitoring and Optimization of NNs (continued)\n",
    "\n",
    "(UCB Datalab AY 128/256; 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-platform",
   "metadata": {},
   "source": [
    "Clearly the parameters we choose will correlate with the quality of the network we build and train\n",
    "<img src=\"https://miro.medium.com/max/2000/1*XgAAoiQ14z8vz-_PMvEVIA.png\">\n",
    "from: https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53\n",
    "\n",
    "We'd like a principled way to \"search\" for the best set of parameters that also protects against overfitting. The simplest thing to do is a *grid search* over all possible parameter combinations. This can be both expensive and somewhat dangerous as this \"greedy search\" will select for a hyperparameter set that happens to get the best score on the validation set and may not generalize well. The next possibility is to do a *random* search over a finite random set of hyperparameters. This has been shown to be superior to grid searches (see Bergstra & Bengio https://www.jmlr.org/papers/v13/bergstra12a.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-functionality",
   "metadata": {},
   "source": [
    "Below is adapted from https://notebook.community/lukas/ml-class/examples/keras-fashion/sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suitable-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "labels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "img_width=28\n",
    "img_height=28\n",
    "\n",
    "# reshape input data\n",
    "X_train = x_train.reshape(x_train.shape[0], img_width, img_height, 1)\n",
    "X_test = x_test.reshape(x_test.shape[0], img_width, img_height, 1)\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-spare",
   "metadata": {},
   "source": [
    "Establish the parameter ranges in a config file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "considered-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {\n",
    "            'values': [2, 5, 10]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [256, 128, 64, 32]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.3, 0.4]\n",
    "        },\n",
    "        'conv_layer_size': {\n",
    "            'values': [16, 32, 64]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0.0005, 0.005]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [1e-2, 1e-3, 1e-4]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'nadam', 'sgd']\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'selu', 'softmax']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-berry",
   "metadata": {},
   "source": [
    "Start a *sweep* project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wired-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gfomdoco\n",
      "Sweep URL: https://wandb.ai/profjsb/ucb-datalab-sweep-2021/sweeps/gfomdoco\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='ucb-datalab-sweep-2021', entity='profjsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recorded-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Default values for hyper-parameters we're going to sweep over\n",
    "    config_defaults = {\n",
    "        'epochs': 5,\n",
    "        'batch_size': 128,\n",
    "        'weight_decay': 0.0005,\n",
    "        'learning_rate': 1e-3,\n",
    "        'activation': 'relu',\n",
    "        'optimizer': 'nadam',\n",
    "        'hidden_layer_size': 128,\n",
    "        'conv_layer_size': 16,\n",
    "        'dropout': 0.5,\n",
    "        'momentum': 0.9,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model architecture - This is a simplified version of the VGG19 architecture\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Set of Conv2D, Conv2D, MaxPooling2D layers with 32 and 64 filters\n",
    "    model.add(tf.keras.layers.Conv2D(filters = config.conv_layer_size, kernel_size = (3, 3), padding = 'same', \n",
    "                     activation ='relu', input_shape=(img_width, img_height,1)))\n",
    "    model.add(tf.keras.layers.Dropout(config.dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters = config.conv_layer_size, kernel_size = (3, 3),\n",
    "                     padding = 'same', activation ='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(config.hidden_layer_size, activation ='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\"))\n",
    "\n",
    "    # Define the optimizer\n",
    "    if config.optimizer=='sgd':\n",
    "      optimizer = tf.keras.optimizers.SGD(lr=config.learning_rate, decay=1e-5, momentum=config.momentum, nesterov=True)\n",
    "    elif config.optimizer=='rmsprop':\n",
    "      optimizer = tf.keras.optimizers.RMSprop(lr=config.learning_rate, decay=1e-5)\n",
    "    elif config.optimizer=='adam':\n",
    "      optimizer = tf.keras.optimizers.Adam(lr=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    elif config.optimizer=='nadam':\n",
    "      optimizer = tf.keras.optimizers.Nadam(lr=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=config.batch_size,\n",
    "              epochs=config.epochs,\n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[WandbCallback(data_type=\"image\", validation_data=(X_test, y_test), labels=labels),\n",
    "                          tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fundamental-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6eehnr3i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: selu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">spring-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021/sweeps/gfomdoco\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021/sweeps/gfomdoco</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/6eehnr3i\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/6eehnr3i</a><br/>\n",
       "                Run data is saved locally in <code>/Users/jbloom/Classes/ay256/course-materials_2021/Lectures/Lecture11_optimization/wandb/run-20210426_135703-6eehnr3i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /Users/jbloom/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.4646 - acc: 0.8356 - val_loss: 0.3900 - val_acc: 0.8522\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 0.2546 - acc: 0.9042 - val_loss: 0.2786 - val_acc: 0.9018\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 94s 2ms/sample - loss: 0.2097 - acc: 0.9201 - val_loss: 0.3039 - val_acc: 0.8935\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.1831 - acc: 0.9302 - val_loss: 0.3410 - val_acc: 0.8807\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.1683 - acc: 0.9371 - val_loss: 0.3156 - val_acc: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 76985<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 9.44MB of 9.44MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.99951259289…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/jbloom/Classes/ay256/course-materials_2021/Lectures/Lecture11_optimization/wandb/run-20210426_135703-6eehnr3i/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/jbloom/Classes/ay256/course-materials_2021/Lectures/Lecture11_optimization/wandb/run-20210426_135703-6eehnr3i/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.16829</td></tr><tr><td>acc</td><td>0.93712</td></tr><tr><td>val_loss</td><td>0.31556</td></tr><tr><td>val_acc</td><td>0.8934</td></tr><tr><td>_runtime</td><td>468</td></tr><tr><td>_timestamp</td><td>1619471091</td></tr><tr><td>_step</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.27864</td></tr><tr><td>best_epoch</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>acc</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▁▃▅▃</td></tr><tr><td>val_acc</td><td>▁█▇▅▇</td></tr><tr><td>_runtime</td><td>▁▃▄▆█</td></tr><tr><td>_timestamp</td><td>▁▃▄▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 181 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-1</strong>: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/6eehnr3i\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/6eehnr3i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ofi3nmsy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">mild-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021/sweeps/gfomdoco\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021/sweeps/gfomdoco</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/ofi3nmsy\" target=\"_blank\">https://wandb.ai/profjsb/ucb-datalab-sweep-2021/runs/ofi3nmsy</a><br/>\n",
       "                Run data is saved locally in <code>/Users/jbloom/Classes/ay256/course-materials_2021/Lectures/Lecture11_optimization/wandb/run-20210426_140502-ofi3nmsy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "40800/60000 [===================>..........] - ETA: 1:08 - loss: 0.4046 - acc: 0.8560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-acoustic",
   "metadata": {},
   "source": [
    "Let's see the results: https://wandb.ai/profjsb/ucb-datalab-sweep-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-italic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
