{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "<style>\n",
       "\n",
       "@import url(https://fonts.googleapis.com/css?family=Open+Sans);body{\n",
       "   font-family: 'Open Sans';\n",
       "   font-size: 125%;\n",
       "}\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 275%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.3; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://en.proft.me/media/science/ml_svlw.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning with scikit-learn\n",
    "\n",
    "Make sure you have version >= 0.19 installed\n",
    "\n",
    "```\n",
    "conda update scikit-learn -y\n",
    "# or...\n",
    "# pip install scikit-learn\n",
    "```\n",
    "\n",
    "See https://scikit-learn.org/stable/\n",
    "\n",
    "also: also: `mlpy`, `orange`, `keras`, `nolearn`, `tensorflow`, `astroML`, … "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://1.bp.blogspot.com/-ME24ePzpzIM/UQLWTwurfXI/AAAAAAAAANw/W3EETIroA80/s1600/drop_shadows_background.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Regression\n",
    "\n",
    "Use training set of $(\\vec x,y)$ pairs to learn to predict $y$ for new $\\vec x$. **Regression** is predicting a *continuous* outcome ($y$) variable from a vector of input features ($\\vec x$). That is, we seek to learn:\n",
    "\n",
    "$f(\\vec x) = y$\n",
    "\n",
    " In \"theory-driven\" MCMC modeling, we already think we know from physics what the functional form of $f$ is and what we try to do is figure out the parameters of $f$ that best accommodate the data we have and the beliefs we start with. When we do not know a functional form for $f$ we take more \"data driven\" approach, such as with Gaussian Processes.\n",
    "\n",
    "In `sklearn` there are a lot of \"data driven\" modelling possibilities.\n",
    "\n",
    "- Linear Regression:  `linear_model.LinearRegression`\n",
    "- Lasso & Ridge Reg.:  `linear_model.Lasso` / `linear_model.Ridge`\n",
    "- Gaussian Process Regression: `gaussian_process.GaussianProcess`\n",
    "- Nearest Neighbor Regression:  `neighbors.KNeighborsRegressor`\n",
    "- Support Vector Regression:   `svm.SVR`\n",
    "- Regression Trees:  `tree.DecisionTreeRegressor`\n",
    "\n",
    "An aside on the \"data driven\" vs \"theory driven\" distinction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression ## \n",
    "\n",
    "Let's take a look at the famous Boston Housing data. We don't have a good physics model for this (of course there are economic theories...). for now we just have data and seek a data-driven model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()  # Boston house-prices\n",
    "X = boston['data']  # 13 features (e.g. crime, # rooms, age, etc.)\n",
    "Y = boston['target']  # response (median house price in $1000)\n",
    "\n",
    "df = pd.DataFrame(X, columns=boston.feature_names)\n",
    "df[\"target\"]  = boston['target']\n",
    "nbins = 5\n",
    "df[\"target_binned\"] = pd.qcut(df[\"target\"], nbins, labels=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"feature vector shape=\", X.shape)\n",
    "print(\"output shape=\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.feature_names)\n",
    "print(type(boston.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some data (Y axis is what we want to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 3, figsize=(12,6))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.scatter(X[:, i], Y, alpha=0.4)\n",
    "    ax.set_xlabel(boston.feature_names[i])\n",
    "    ax.set_ylabel(\"Median House Price (in $1000)\")\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "point_size = 80*(Y/max(Y))**3\n",
    "\n",
    "df1 = df[['AGE', 'DIS', 'RAD', 'TAX', \"target_binned\"]]\n",
    "colors = sns.color_palette(\"colorblind\", nbins)\n",
    "\n",
    "g= sns.pairplot(df1, hue=\"target_binned\", palette=sns.color_palette(\"cubehelix\", nbins),\n",
    "                         plot_kws=dict(s=point_size, edgecolor=None, alpha=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model Fitting\n",
    "\n",
    "We need to create a **training set** and a **testing set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half of data\n",
    "import math\n",
    "half = math.floor(len(Y)/2)\n",
    "train_X = X[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X[half:]\n",
    "test_Y = Y[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the input variables. In mathematical notion, if $\\hat{y}$ is the predicted value.\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
    "Across the module, we designate the vector $w = (w_1,\n",
    "..., w_p)$ as `coef_` and $w_0$ as `intercept_`.\n",
    "To perform classification with generalized linear models, see Logistic regression.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the prediction\n",
    "Y_lr_pred = clf.predict(test_X)\n",
    "\n",
    "# how well did we do?\n",
    "mse = mean_squared_error(test_Y,Y_lr_pred) ; print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(test_Y,Y_lr_pred - test_Y, 'o')\n",
    "ax.set_title(\"Linear Regression Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($1,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *k*-Nearest Neighbor (KNN) Regression\n",
    "\n",
    "\"The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data (possibly transformed into a fast indexing structure such as a Ball Tree or KD Tree.).\"\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_regression_001.png\">\n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# many methods work better on scaled X\n",
    "scaler = preprocessing.PowerTransformer() \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf1 = neighbors.KNeighborsRegressor(5)\n",
    "\n",
    "# scale\n",
    "train_X = X_scaled[:half]\n",
    "test_X = X_scaled[half:]\n",
    "\n",
    "# not scaled\n",
    "#train_X = X[:half]\n",
    "#test_X = X[half:]\n",
    "\n",
    "\n",
    "clf1.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_knn_pred = clf1.predict(test_X)\n",
    "mse = mean_squared_error(test_Y,Y_knn_pred) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(test_Y, Y_knn_pred - test_Y, 'o', alpha=0.4)\n",
    "ax.set_title(\"k-NN Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True Median House Price ($1,000)\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what other datasets are readily available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these we need to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_house = datasets.california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data = cal_house.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cal_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cal_data['data'] # 8 features \n",
    "Y = cal_data['target'] # response (median house price)\n",
    "half = math.floor(len(Y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# remember: many methods work better on scaled X\n",
    "X_scaled = preprocessing.scale(X) \n",
    "train_X = X_scaled[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X_scaled[half:]\n",
    "test_Y = Y[half:]\n",
    "clf1 = neighbors.KNeighborsRegressor(10)\n",
    "clf1.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "Y_knn_pred = clf1.predict(test_X)\n",
    "mse = mean_squared_error(test_Y,Y_knn_pred) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(test_Y, Y_knn_pred - test_Y,alpha=0.2,edgecolors=None)\n",
    "ax.set_title(\"k-NN Residuals - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True log normalized Median House Price\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")\n",
    "ax.set_xlim(0,5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Estimation & Model Selection\n",
    "\n",
    "**Q**: How will our model perform on future data?\n",
    "\n",
    "So far, we’ve split the data, using one set to train the model and the other to test its performance\n",
    "\n",
    "This train-test strategy avoids over-fitting to the sample on hand, but wastes data & can produce poor error estimates.\n",
    "\n",
    "cf. https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "### model selection: cross-validation\n",
    "\n",
    "\n",
    "- *K-fold CV* - randomly split the training data into K \"folds.\"  For each $k=1,...,K$, train model only on the data not in fold $k$ & predict for data in fold $k$.  Compute performance metric over CV predictions.\n",
    "\n",
    "- *Leave-one-out (LOO) CV* -- n-fold CV with  n = number of training points.\n",
    "\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUWvg9caKz1OO7opS2Ji3Z7OwOFkLCrg2WsB/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://i.stack.imgur.com/YWgro.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "boston = datasets.california_housing.fetch_california_housing()\n",
    "\n",
    "X = boston['data'] ; y = boston['target']\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def print_cv_score_summary(model, xx, yy, cv, verbose=False):\n",
    "    scores = cross_val_score(model, xx, yy, cv=cv, n_jobs=1, verbose=verbose)\n",
    "    print(\"mean: {:3f}, stdev: {:3f}\".format(\n",
    "        np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "print_cv_score_summary(clf, X, y,\n",
    "                       cv=model_selection.KFold(10, shuffle=True, random_state = 42), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(clf, X, y, cv=model_selection.KFold(10, shuffle=True, random_state = 42), n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y, predictions) ; print(mse)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y, predictions - y,alpha=0.2,edgecolors=None)\n",
    "ax.set_title(\"CV kfold linear model - MSE = %.1f\" % mse)\n",
    "ax.set_xlabel(\"True log normalized Median House Price\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.hlines(0,min(test_Y),max(test_Y),color=\"red\")\n",
    "ax.set_xlim(0,5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = neighbors.KNeighborsRegressor(15)\n",
    "print_cv_score_summary(clf_knn, X, y,\n",
    "                       cv=model_selection.KFold(5, shuffle=True, random_state = 42), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.KNeighborsRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"n_neighbors\": [5, 8, 10, 12, 15, 20],  \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "knn_tune = model_selection.GridSearchCV(clf_knn, parameters, \n",
    "                                   n_jobs = -1, cv = 10, verbose=True, scoring='neg_mean_squared_error')\n",
    "\n",
    "knn_opt = knn_tune.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
